
---
title: "ST558- Final Project, Modeling File"
author: "Alex Devoid"
date: "July 29, 2024"
format: html
---


# Introduction

This document details the modeling process for predicting the `Diabetes_binary` outcome using various machine learning techniques, including Logistic Regression, Classification Tree, and Random Forest. We utilize the `caret` package for model training and evaluation, employing log loss as our primary metric.

## Log Loss and Its Importance

Log loss, or logarithmic loss, measures the accuracy of a classification model by penalizing false classifications. Unlike accuracy, which simply counts correct classifications, log loss takes into account the confidence of the predictions, giving higher penalties for confident but wrong predictions. This makes log loss particularly suitable for situations where understanding the certainty of predictions is crucial, such as medical diagnosis.

## Data Preparation

The dataset has been split into training and testing sets, with 70% allocated to training and 30% to testing. We have also scaled the numerical features and encoded categorical variables as factors, following the same data cleaning procedures used in the EDA.

```{r}
# Load necessary libraries
library(caret)
library(dplyr)

# Load the data
data <- read.csv("../diabetes_binary_health_indicators_BRFSS2015.csv")

# Convert categorical variables to factors with descriptive labels
data <- data %>%
  mutate(
    Diabetes_binary = factor(Diabetes_binary, levels = c(0, 1), labels = c("No", "Yes")),
    HighBP = factor(HighBP, levels = c(0, 1), labels = c("No", "Yes")),
    HighChol = factor(HighChol, levels = c(0, 1), labels = c("No", "Yes")),
    CholCheck = factor(CholCheck, levels = c(0, 1), labels = c("No", "Yes")),
    Smoker = factor(Smoker, levels = c(0, 1), labels = c("Non-smoker", "Smoker")),
    PhysActivity = factor(PhysActivity, levels = c(0, 1), labels = c("No", "Yes")),
    Fruits = factor(Fruits, levels = c(0, 1), labels = c("No", "Yes")),
    Veggies = factor(Veggies, levels = c(0, 1), labels = c("No", "Yes")),
    GeneralHealth = factor(GenHlth, levels = c(1:5), labels = c("Excellent", "Very Good", "Good", "Fair", "Poor")),
    Sex = factor(Sex, levels = c(0, 1), labels = c("Female", "Male")),
    Age = factor(Age, levels = 1:13, labels = c("18-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59", "60-64", "65-69", "70-74", "75-79", "80+"))
  )

# Handle missing values if necessary
# Example: Replace NA in BMI with median
data$BMI[is.na(data$BMI)] <- median(data$BMI, na.rm = TRUE)

# Log the levels of Diabetes_binary for verification
cat("Levels of Diabetes_binary:\n")
print(levels(data$Diabetes_binary))

# Split the data
set.seed(42)
trainIndex <- createDataPartition(data$Diabetes_binary, p = .7, list = FALSE)
training_data <- data[trainIndex,]
testing_data <- data[-trainIndex,]

# Standardize numerical features (if any)
preProcess_scale <- preProcess(training_data[, sapply(training_data, is.numeric)], method = c("center", "scale"))
training_data_scaled <- predict(preProcess_scale, training_data[, sapply(training_data, is.numeric)])
testing_data_scaled <- predict(preProcess_scale, testing_data[, sapply(testing_data, is.numeric)])

# Reattach the response variable and other factor variables
training_data_scaled <- cbind(training_data_scaled, training_data[, sapply(training_data, is.factor)])
testing_data_scaled <- cbind(testing_data_scaled, testing_data[, sapply(testing_data, is.factor)])

# Log final check of levels for all factors
cat("Final levels of all factors in the dataset:\n")
sapply(training_data_scaled, levels)
```

# Logistic Regression

Logistic regression is a statistical model used for binary classification tasks. It predicts the probability of an outcome that can only take two possible values (like having diabetes or not). Logistic regression is appropriate here because our response variable, `Diabetes_binary`, is binary.

## Model Training

We use the `caret` package to fit three candidate logistic regression models with different sets of predictors. The best model is selected based on log loss.

```{r}
# Training control setup for cross-validation
train_control <- trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = mnLogLoss)

# Logistic regression model training
logistic_model <- train(Diabetes_binary ~ ., data = training_data_scaled, method = "glm", family = "binomial", trControl = train_control)

# Display the best logistic model

save(logistic_model, file = "logistic_model.RData")
```

# Classification Tree

A classification tree is a type of decision tree that is used for classifying a dataset into distinct classes. It works by splitting the dataset into branches based on feature values that best separate the classes.

## Model Training

We use `caret` to fit a classification tree model with different complexity parameters. The best model is selected using cross-validated log loss.

```{r}
# Classification tree model training
tree_model <- train(Diabetes_binary ~ ., data = training_data_scaled, method = "rpart", trControl = train_control, tuneGrid = expand.grid(cp = c(0.01, 0.05, 0.1)))

# Display the best classification tree model

save(tree_model, file = "tree_model.RData")
```

# Random Forest

Random forests are an ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes as the prediction. It helps in improving accuracy and controlling overfitting.

## Model Training

We fit a random forest model with different numbers of trees and maximum features considered at each split. The best model is selected based on log loss.

```{r}
# Random forest model training
rf_model <- train(Diabetes_binary ~ ., 
                  data = training_data_scaled, 
                  method = "rf", 
                  trControl = train_control, 
                  tuneGrid = expand.grid(mtry = c(2)), 
                  ntree = 50)

# Display the best random forest model

save(rf_model, file = "random_forest.RData")
```

# Final Model Selection

After fitting the models, we compare their performance on the test set using log loss and select the best-performing model.

```{r}
# Predictions on the test set
logistic_pred <- predict(logistic_model, newdata = testing_data_scaled, type = "prob")[, 2]
tree_pred <- predict(tree_model, newdata = testing_data_scaled, type = "prob")[, 2]
rf_pred <- predict(rf_model, newdata = testing_data_scaled, type = "prob")[, 2]

# Calculating log loss for each model
logistic_loss <- LogLoss(testing_data$Diabetes_binary, logistic_pred)
tree_loss <- LogLoss(testing_data$Diabetes_binary, tree_pred)
rf_loss <- LogLoss(testing_data$Diabetes_binary, rf_pred)

# Output the log loss for each model
logistic_loss
tree_loss
rf_loss
```

# Conclusion

The modeling process involved fitting and evaluating three types of models: Logistic Regression, Classification Tree, and Random Forest. We used log loss as the evaluation metric and selected the best model based on performance on the test set. The selected model will be further tuned and validated before deployment.

